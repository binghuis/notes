> 词嵌入（Word embedding）是自然语言处理（NLP）中语言模型与表征学习技术的统称。概念上而言，它是指把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。


### 10000个单词使用one hot,整数编码和embedding之后的数据，维度分别是多少？

假设词汇表中有10,000个不同的单词，我们来看一下在使用 one-hot 编码、整数编码和嵌入（embedding）后的数据维度。

One-hot 编码：
使用 one-hot 编码时，每个单词将被表示为一个长度为 10,000 的向量，其中只有一个元素为1，其他 9,999 个元素都为0。因此，one-hot 编码后的数据维度为 (10,000, 10,000)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 10,000 维的向量。

整数编码：
使用整数编码时，每个单词将被映射为一个整数值。因为词汇表中有 10,000 个不同的单词，所以整数编码后的数据仍然是一个长度为 10,000 的向量。整数编码后的数据维度为 (10,000, 1)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 1 维的整数值。

嵌入（Embedding）：
在嵌入过程中，每个单词将被映射为一个低维的嵌入向量。通常情况下，词汇表中的每个单词都有一个对应的嵌入向量。假设我们使用一个100维的嵌入空间（这个维度可以根据任务需求进行调整），那么经过嵌入后的数据维度为 (10,000, 100)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 100 维的嵌入向量。

总结：

One-hot 编码后的数据维度：(10,000, 10,000)
整数编码后的数据维度：(10,000, 1)
嵌入后的数据维度：(10,000, 100) (假设使用100维的嵌入空间)

### 那么嵌入后的数据维度相对于整数编码后的数据维度并没有降维是吗？

对的，嵌入后的数据维度相对于整数编码后的数据维度并没有降维。

在嵌入（embedding）过程中，每个单词将被映射为一个低维的嵌入向量。在我们的例子中，假设使用一个100维的嵌入空间，那么嵌入后的数据维度为 (10,000, 100)。每个样本（单词）被映射为一个100维的嵌入向量。

相较于整数编码后的数据维度 (10,000, 1)，嵌入后的数据维度 (10,000, 100) 并没有降维，而是将单词从一个整数值转换为一个100维的连续向量表示。这样的嵌入向量是一个低维的、密集的向量，相对于 one-hot 编码数据维度 (10,000, 10,000)，它确实实现了维度的降低，但相对于整数编码后的数据，它并没有降维。

嵌入向量的目标是将原始的离散数据（整数编码）映射到一个连续的向量空间中，以便于更好地捕捉单词之间的语义关系和相似性。虽然维度上没有实现严格的降维，但是通过这种映射，嵌入向量能够更好地表示单词之间的语义信息，并在自然语言处理任务中表现出更好的性能。

### 离散数据是什么？

离散数据是一种数据类型，它是一组具有有限或可数的值的数据。在离散数据中，每个值之间存在明确的间隔，并且没有可能的取值在这些间隔之间。

离散数据与连续数据相对。在连续数据中，取值可以在某个区间内的任意值，而不仅仅限于一些明确的预定义值。

在自然语言处理（NLP）中，单词是一种典型的离散数据。每个单词属于词汇表中的一个离散类别，而且每个单词之间是相互独立的，不存在介于两个单词之间的其他单词。因此，在NLP中，我们通常需要将离散的单词数据转换为连续的嵌入向量（embedding vector）表示，以便于进行文本处理和机器学习任务。

除了单词，其他一些离散数据的例子包括：类别标签、性别、地区等等。与之相对的连续数据的例子包括：身高、体重、温度、时间等等。