> 词嵌入（Word embedding）是自然语言处理（NLP）中语言模型与表征学习技术的统称。概念上而言，它是指把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量。


### 10000个单词使用one hot,整数编码和embedding之后的数据，维度分别是多少？

假设词汇表中有10,000个不同的单词，我们来看一下在使用 one-hot 编码、整数编码和嵌入（embedding）后的数据维度。

One-hot 编码：
使用 one-hot 编码时，每个单词将被表示为一个长度为 10,000 的向量，其中只有一个元素为1，其他 9,999 个元素都为0。因此，one-hot 编码后的数据维度为 (10,000, 10,000)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 10,000 维的向量。

整数编码：
使用整数编码时，每个单词将被映射为一个整数值。因为词汇表中有 10,000 个不同的单词，所以整数编码后的数据仍然是一个长度为 10,000 的向量。整数编码后的数据维度为 (10,000, 1)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 1 维的整数值。

嵌入（Embedding）：
在嵌入过程中，每个单词将被映射为一个低维的嵌入向量。通常情况下，词汇表中的每个单词都有一个对应的嵌入向量。假设我们使用一个100维的嵌入空间（这个维度可以根据任务需求进行调整），那么经过嵌入后的数据维度为 (10,000, 100)，其中 10,000 是词汇表中单词的数量，表示有 10,000 个样本，每个样本是一个 100 维的嵌入向量。

总结：

One-hot 编码后的数据维度：(10,000, 10,000)
整数编码后的数据维度：(10,000, 1)
嵌入后的数据维度：(10,000, 100) (假设使用100维的嵌入空间)

### 那么嵌入后的数据维度相对于整数编码后的数据维度并没有降维是吗？

对的，嵌入后的数据维度相对于整数编码后的数据维度并没有降维。

在嵌入（embedding）过程中，每个单词将被映射为一个低维的嵌入向量。在我们的例子中，假设使用一个100维的嵌入空间，那么嵌入后的数据维度为 (10,000, 100)。每个样本（单词）被映射为一个100维的嵌入向量。

相较于整数编码后的数据维度 (10,000, 1)，嵌入后的数据维度 (10,000, 100) 并没有降维，而是将单词从一个整数值转换为一个100维的连续向量表示。这样的嵌入向量是一个低维的、密集的向量，相对于 one-hot 编码数据维度 (10,000, 10,000)，它确实实现了维度的降低，但相对于整数编码后的数据，它并没有降维。

嵌入向量的目标是将原始的离散数据（整数编码）映射到一个连续的向量空间中，以便于更好地捕捉单词之间的语义关系和相似性。虽然维度上没有实现严格的降维，但是通过这种映射，嵌入向量能够更好地表示单词之间的语义信息，并在自然语言处理任务中表现出更好的性能。

### 离散数据是什么？

离散数据是一种数据类型，它是一组具有有限或可数的值的数据。在离散数据中，每个值之间存在明确的间隔，并且没有可能的取值在这些间隔之间。

离散数据与连续数据相对。在连续数据中，取值可以在某个区间内的任意值，而不仅仅限于一些明确的预定义值。

在自然语言处理（NLP）中，单词是一种典型的离散数据。每个单词属于词汇表中的一个离散类别，而且每个单词之间是相互独立的，不存在介于两个单词之间的其他单词。因此，在NLP中，我们通常需要将离散的单词数据转换为连续的嵌入向量（embedding vector）表示，以便于进行文本处理和机器学习任务。

除了单词，其他一些离散数据的例子包括：类别标签、性别、地区等等。与之相对的连续数据的例子包括：身高、体重、温度、时间等等。

# 聚类算法

K-Means（K均值）是一种常用的聚类算法，用于将数据集中的样本分成K个不同的簇（cluster）。这个算法的目标是将样本划分成K个簇，使得每个样本点与其所属簇的质心（簇的中心点）之间的距离最小化，同时确保每个样本点只属于一个簇。

K-Means算法的工作流程如下：

随机选择K个点作为初始的质心（聚类中心）。

将每个样本点分配到距离最近的质心所代表的簇中。

计算每个簇的质心，即簇内所有样本的平均值。

重复步骤2和步骤3，直到簇不再发生变化，或者达到预定的迭代次数。

K-Means算法通过迭代的方式将样本点划分成K个簇，使得簇内的样本点相似度较高，而不同簇之间的样本点相似度较低。这样的聚类过程可以帮助我们发现数据中的隐藏结构，进行数据压缩、数据分类、异常检测等应用。

需要注意的是，K-Means算法对于K值的选择较为敏感。不同的K值可能会导致不同的聚类结果，因此通常需要通过尝试不同的K值，并使用一些评估指标（如轮廓系数、内聚性、分离性等）来选择最优的K值。另外，K-Means算法对于数据分布的假设是各簇呈现球形，对于非球形的数据分布，可能会得到不太理想的结果。因此，在使用K-Means算法时需要对数据进行预处理和适当的特征工程。